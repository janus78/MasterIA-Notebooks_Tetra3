{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Actividad Semana 3 - Pregunta 3\n",
    "**Pregunta 3**\n",
    "Se presenta a continuación el ejercicio tomando como ejemplo una implementación tutorial encontrada en la web donde se ejemplifica el uso del backpropagation para aprender la tabla XOR.\n",
    "Dadas las entradas X0 y X1, predecir la salida Y.\n",
    "\n",
    "| X0 | X1 | Y |\n",
    "|----|----|---|\n",
    "| 0  |  0 | 0 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 1  | 1  | 0 |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea una clase que va a contener las propiedades y métodos de la red neuronal."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, alpha=0.1):\n",
    "        #Se inicializa la red con los parámetros de entrada\n",
    "        #Como la matriz de pesos la cantidad de capas y el rango de aprendizaje\n",
    "        self.W = []\n",
    "        self.layers = layers\n",
    "        self.alpha = alpha\n",
    "        self.epoch_data = []\n",
    "        self.loss_data = []\n",
    "\n",
    "        #En este loop se recorre del indice de la primera capa pero se detiene antes de llegar a las últimas dos capas\n",
    "        for i in np.arange(0, len(layers) - 2):\n",
    "            #Se inicializa la matriz de peso de forma aleatoria\n",
    "            w = np.random.randn(layers[i] + 1, layers[i + 1] + 1)\n",
    "            self.W.append(w / np.sqrt(layers[i]))\n",
    "            w = np.random.randn(layers[-2] + 1, layers[-1])\n",
    "            self.W.append(w / np.sqrt(layers[-2]))\n",
    "\n",
    "    #Se define la función de activación\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    #Se define la función de activación derivada\n",
    "    def sigmoid_deriv(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    #Esta función será la responsable de entrenar a la red neural\n",
    "    def fit(self, X, y, epochs=1000, displayUpdate=100):\n",
    "        #Se inserta una columna de 1's al final de la matriz de entrada para que la capa de entrada tenga una entrada de bias\n",
    "        X = np.c_[X, np.ones((X.shape[0]))]\n",
    "\n",
    "        #Se cicla entre el número de epochs\n",
    "        for epoch in np.arange(0, epochs):\n",
    "            #Se cicla entre cada dato y se entrena la red para ese dato\n",
    "            for (x, target) in zip(X, y):\n",
    "                self.fit_partial(x, target)\n",
    "\n",
    "                #Aquí se decide si mostrar o no el resultado de cada epoch\n",
    "                if epoch == 0 or (epoch + 1) % displayUpdate == 0:\n",
    "                    loss = self.calculate_loss(X, y)\n",
    "                    print(\"Epoch: {}\".format(epoch + 1), \"Loss: {:.2f}\".format(loss))\n",
    "            #Se guardan los datos del epoch y la pérdida para la gráfica\n",
    "            self.epoch_data.append(epoch)\n",
    "            self.loss_data.append(loss)\n",
    "\n",
    "    #Esta función contiene el algoritmo de propagacion hacia atrás de la red\n",
    "    def fit_partial(self, x, y):\n",
    "        A = [np.atleast_2d(x)]\n",
    "\n",
    "        #Esta parte es la propagación hacia adelante\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            #Con esto se calcula la entrada neta con el producto punto entre la activación anterior y el peso\n",
    "            net = A[layer].dot(self.W[layer])\n",
    "            #Para obtener la salida neta se aplica la función de activación\n",
    "            out = self.sigmoid(net)\n",
    "            #La salida se agrega a la lista de activaciones\n",
    "            A.append(out)\n",
    "\n",
    "            #Esta parte es la propagación hacia atrás\n",
    "            #Se obtiene la diferencia entre la salida y el valor deseado\n",
    "            error =A[-1] - y\n",
    "\n",
    "            #Aquí se aplica la regla de la cadena para calcular el gradiente\n",
    "            #La primera entrada es el error de la capa de salida multiplicado por la función de activación derivada\n",
    "            D = [error * self.sigmoid_deriv(A[-1])]\n",
    "\n",
    "            #Aqui se recorren las capas hacia atrás ignorando las dos últimas\n",
    "            for layer in np.arange(len(A) - 2, 0, -1):\n",
    "                #El gradiente de la capa actual es igual al gradiente de la capa anterior\n",
    "                # multiplicado por la matriz de pesos de la capa actual\n",
    "                #y multiplicado por la función de activación derivada de la capa actual\n",
    "                delta = D[-1].dot(self.W[layer].T)\n",
    "                delta = delta * self.sigmoid_deriv(A[layer])\n",
    "                D.append(delta)\n",
    "                #Como se cicló hacia atrás, se cambia el orden de la lista\n",
    "                D = D[::-1]\n",
    "                #Fase de actualización de los pesos\n",
    "                for layer in np.arange(0, len(self.W)):\n",
    "                    # Se actualizan los pesos de la capa actual multiplicando las capas de activacion por el gradiente\n",
    "                    #y multiplicando este valor por el rango de aprendizaje agregando la matriz de pesos\n",
    "                    #En este punto es donde se realiza el aprendizaje\n",
    "                    self.W[layer] += -self.alpha * A[layer].T.dot(D[layer])\n",
    "\n",
    "    def predict(self, X, addBias=True):\n",
    "        #Se inicializa la predicción que será propagada hacia adelante para obtener la predicción final\n",
    "        p = np.atleast_2d(X)\n",
    "        #Se valida si se requiere la adición de una entrada de bias\n",
    "        if addBias:\n",
    "            #se inserta una columna de 1's al final de la matriz de entrada para que la capa de entrada tenga una entrada de bias\n",
    "            p = np.c_[p, np.ones((p.shape[0]))]\n",
    "\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            #Se obtiene la predicción de salida con el producto punto entre la activación actual y el peso\n",
    "            #Y se envía a la función de activación\n",
    "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
    "        return p\n",
    "\n",
    "    #Se calcula la pérdida de todo el set de datos\n",
    "    def calculate_loss(self, X, targets):\n",
    "        targets = np.atleast_2d(targets)\n",
    "        predictions = self.predict(X, addBias=False)\n",
    "        loss = 0.5 * np.sum((predictions - targets) ** 2)\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.51\n",
      "Epoch: 1 Loss: 0.51\n",
      "Epoch: 1 Loss: 0.51\n",
      "Epoch: 1 Loss: 0.51\n",
      "Epoch: 100 Loss: 0.50\n",
      "Epoch: 100 Loss: 0.50\n",
      "Epoch: 100 Loss: 0.50\n",
      "Epoch: 100 Loss: 0.50\n",
      "Epoch: 200 Loss: 0.50\n",
      "Epoch: 200 Loss: 0.50\n",
      "Epoch: 200 Loss: 0.50\n",
      "Epoch: 200 Loss: 0.50\n",
      "Epoch: 300 Loss: 0.50\n",
      "Epoch: 300 Loss: 0.50\n",
      "Epoch: 300 Loss: 0.50\n",
      "Epoch: 300 Loss: 0.50\n",
      "Epoch: 400 Loss: 0.49\n",
      "Epoch: 400 Loss: 0.49\n",
      "Epoch: 400 Loss: 0.49\n",
      "Epoch: 400 Loss: 0.49\n",
      "Epoch: 500 Loss: 0.47\n",
      "Epoch: 500 Loss: 0.47\n",
      "Epoch: 500 Loss: 0.47\n",
      "Epoch: 500 Loss: 0.47\n",
      "Epoch: 600 Loss: 0.41\n",
      "Epoch: 600 Loss: 0.41\n",
      "Epoch: 600 Loss: 0.41\n",
      "Epoch: 600 Loss: 0.41\n",
      "Epoch: 700 Loss: 0.34\n",
      "Epoch: 700 Loss: 0.34\n",
      "Epoch: 700 Loss: 0.34\n",
      "Epoch: 700 Loss: 0.34\n",
      "Epoch: 800 Loss: 0.27\n",
      "Epoch: 800 Loss: 0.27\n",
      "Epoch: 800 Loss: 0.27\n",
      "Epoch: 800 Loss: 0.27\n",
      "Epoch: 900 Loss: 0.21\n",
      "Epoch: 900 Loss: 0.21\n",
      "Epoch: 900 Loss: 0.21\n",
      "Epoch: 900 Loss: 0.21\n",
      "Epoch: 1000 Loss: 0.18\n",
      "Epoch: 1000 Loss: 0.18\n",
      "Epoch: 1000 Loss: 0.18\n",
      "Epoch: 1000 Loss: 0.18\n",
      "Epoch: 1100 Loss: 0.16\n",
      "Epoch: 1100 Loss: 0.16\n",
      "Epoch: 1100 Loss: 0.16\n",
      "Epoch: 1100 Loss: 0.16\n",
      "Epoch: 1200 Loss: 0.15\n",
      "Epoch: 1200 Loss: 0.15\n",
      "Epoch: 1200 Loss: 0.15\n",
      "Epoch: 1200 Loss: 0.15\n",
      "Epoch: 1300 Loss: 0.15\n",
      "Epoch: 1300 Loss: 0.15\n",
      "Epoch: 1300 Loss: 0.15\n",
      "Epoch: 1300 Loss: 0.15\n",
      "Epoch: 1400 Loss: 0.14\n",
      "Epoch: 1400 Loss: 0.14\n",
      "Epoch: 1400 Loss: 0.14\n",
      "Epoch: 1400 Loss: 0.14\n",
      "Epoch: 1500 Loss: 0.14\n",
      "Epoch: 1500 Loss: 0.14\n",
      "Epoch: 1500 Loss: 0.14\n",
      "Epoch: 1500 Loss: 0.14\n",
      "Epoch: 1600 Loss: 0.14\n",
      "Epoch: 1600 Loss: 0.14\n",
      "Epoch: 1600 Loss: 0.14\n",
      "Epoch: 1600 Loss: 0.14\n",
      "Epoch: 1700 Loss: 0.14\n",
      "Epoch: 1700 Loss: 0.14\n",
      "Epoch: 1700 Loss: 0.14\n",
      "Epoch: 1700 Loss: 0.14\n",
      "Epoch: 1800 Loss: 0.13\n",
      "Epoch: 1800 Loss: 0.13\n",
      "Epoch: 1800 Loss: 0.13\n",
      "Epoch: 1800 Loss: 0.13\n",
      "Epoch: 1900 Loss: 0.13\n",
      "Epoch: 1900 Loss: 0.13\n",
      "Epoch: 1900 Loss: 0.13\n",
      "Epoch: 1900 Loss: 0.13\n",
      "Epoch: 2000 Loss: 0.13\n",
      "Epoch: 2000 Loss: 0.13\n",
      "Epoch: 2000 Loss: 0.13\n",
      "Epoch: 2000 Loss: 0.13\n",
      "Epoch: 2100 Loss: 0.13\n",
      "Epoch: 2100 Loss: 0.13\n",
      "Epoch: 2100 Loss: 0.13\n",
      "Epoch: 2100 Loss: 0.13\n",
      "Epoch: 2200 Loss: 0.13\n",
      "Epoch: 2200 Loss: 0.13\n",
      "Epoch: 2200 Loss: 0.13\n",
      "Epoch: 2200 Loss: 0.13\n",
      "Epoch: 2300 Loss: 0.13\n",
      "Epoch: 2300 Loss: 0.13\n",
      "Epoch: 2300 Loss: 0.13\n",
      "Epoch: 2300 Loss: 0.13\n",
      "Epoch: 2400 Loss: 0.13\n",
      "Epoch: 2400 Loss: 0.13\n",
      "Epoch: 2400 Loss: 0.13\n",
      "Epoch: 2400 Loss: 0.13\n",
      "Epoch: 2500 Loss: 0.13\n",
      "Epoch: 2500 Loss: 0.13\n",
      "Epoch: 2500 Loss: 0.13\n",
      "Epoch: 2500 Loss: 0.13\n",
      "Epoch: 2600 Loss: 0.13\n",
      "Epoch: 2600 Loss: 0.13\n",
      "Epoch: 2600 Loss: 0.13\n",
      "Epoch: 2600 Loss: 0.13\n",
      "Epoch: 2700 Loss: 0.13\n",
      "Epoch: 2700 Loss: 0.13\n",
      "Epoch: 2700 Loss: 0.13\n",
      "Epoch: 2700 Loss: 0.13\n",
      "Epoch: 2800 Loss: 0.13\n",
      "Epoch: 2800 Loss: 0.13\n",
      "Epoch: 2800 Loss: 0.13\n",
      "Epoch: 2800 Loss: 0.13\n",
      "Epoch: 2900 Loss: 0.13\n",
      "Epoch: 2900 Loss: 0.13\n",
      "Epoch: 2900 Loss: 0.13\n",
      "Epoch: 2900 Loss: 0.13\n",
      "Epoch: 3000 Loss: 0.13\n",
      "Epoch: 3000 Loss: 0.13\n",
      "Epoch: 3000 Loss: 0.13\n",
      "Epoch: 3000 Loss: 0.13\n",
      "Epoch: 3100 Loss: 0.13\n",
      "Epoch: 3100 Loss: 0.13\n",
      "Epoch: 3100 Loss: 0.13\n",
      "Epoch: 3100 Loss: 0.13\n",
      "Epoch: 3200 Loss: 0.13\n",
      "Epoch: 3200 Loss: 0.13\n",
      "Epoch: 3200 Loss: 0.13\n",
      "Epoch: 3200 Loss: 0.13\n",
      "Epoch: 3300 Loss: 0.13\n",
      "Epoch: 3300 Loss: 0.13\n",
      "Epoch: 3300 Loss: 0.13\n",
      "Epoch: 3300 Loss: 0.13\n",
      "Epoch: 3400 Loss: 0.13\n",
      "Epoch: 3400 Loss: 0.13\n",
      "Epoch: 3400 Loss: 0.13\n",
      "Epoch: 3400 Loss: 0.13\n",
      "Epoch: 3500 Loss: 0.13\n",
      "Epoch: 3500 Loss: 0.13\n",
      "Epoch: 3500 Loss: 0.13\n",
      "Epoch: 3500 Loss: 0.13\n",
      "Epoch: 3600 Loss: 0.13\n",
      "Epoch: 3600 Loss: 0.13\n",
      "Epoch: 3600 Loss: 0.13\n",
      "Epoch: 3600 Loss: 0.13\n",
      "Epoch: 3700 Loss: 0.13\n",
      "Epoch: 3700 Loss: 0.13\n",
      "Epoch: 3700 Loss: 0.13\n",
      "Epoch: 3700 Loss: 0.13\n",
      "Epoch: 3800 Loss: 0.13\n",
      "Epoch: 3800 Loss: 0.13\n",
      "Epoch: 3800 Loss: 0.13\n",
      "Epoch: 3800 Loss: 0.13\n",
      "Epoch: 3900 Loss: 0.13\n",
      "Epoch: 3900 Loss: 0.13\n",
      "Epoch: 3900 Loss: 0.13\n",
      "Epoch: 3900 Loss: 0.13\n",
      "Epoch: 4000 Loss: 0.13\n",
      "Epoch: 4000 Loss: 0.13\n",
      "Epoch: 4000 Loss: 0.13\n",
      "Epoch: 4000 Loss: 0.13\n",
      "Epoch: 4100 Loss: 0.13\n",
      "Epoch: 4100 Loss: 0.13\n",
      "Epoch: 4100 Loss: 0.13\n",
      "Epoch: 4100 Loss: 0.13\n",
      "Epoch: 4200 Loss: 0.13\n",
      "Epoch: 4200 Loss: 0.13\n",
      "Epoch: 4200 Loss: 0.13\n",
      "Epoch: 4200 Loss: 0.13\n",
      "Epoch: 4300 Loss: 0.13\n",
      "Epoch: 4300 Loss: 0.13\n",
      "Epoch: 4300 Loss: 0.13\n",
      "Epoch: 4300 Loss: 0.13\n",
      "Epoch: 4400 Loss: 0.13\n",
      "Epoch: 4400 Loss: 0.13\n",
      "Epoch: 4400 Loss: 0.13\n",
      "Epoch: 4400 Loss: 0.13\n",
      "Epoch: 4500 Loss: 0.13\n",
      "Epoch: 4500 Loss: 0.13\n",
      "Epoch: 4500 Loss: 0.13\n",
      "Epoch: 4500 Loss: 0.13\n",
      "Epoch: 4600 Loss: 0.13\n",
      "Epoch: 4600 Loss: 0.13\n",
      "Epoch: 4600 Loss: 0.13\n",
      "Epoch: 4600 Loss: 0.13\n",
      "Epoch: 4700 Loss: 0.13\n",
      "Epoch: 4700 Loss: 0.13\n",
      "Epoch: 4700 Loss: 0.13\n",
      "Epoch: 4700 Loss: 0.13\n",
      "Epoch: 4800 Loss: 0.13\n",
      "Epoch: 4800 Loss: 0.13\n",
      "Epoch: 4800 Loss: 0.13\n",
      "Epoch: 4800 Loss: 0.13\n",
      "Epoch: 4900 Loss: 0.13\n",
      "Epoch: 4900 Loss: 0.13\n",
      "Epoch: 4900 Loss: 0.13\n",
      "Epoch: 4900 Loss: 0.13\n",
      "Epoch: 5000 Loss: 0.13\n",
      "Epoch: 5000 Loss: 0.13\n",
      "Epoch: 5000 Loss: 0.13\n",
      "Epoch: 5000 Loss: 0.13\n",
      "Epoch: 5100 Loss: 0.13\n",
      "Epoch: 5100 Loss: 0.13\n",
      "Epoch: 5100 Loss: 0.13\n",
      "Epoch: 5100 Loss: 0.13\n",
      "Epoch: 5200 Loss: 0.13\n",
      "Epoch: 5200 Loss: 0.13\n",
      "Epoch: 5200 Loss: 0.13\n",
      "Epoch: 5200 Loss: 0.13\n",
      "Epoch: 5300 Loss: 0.13\n",
      "Epoch: 5300 Loss: 0.13\n",
      "Epoch: 5300 Loss: 0.13\n",
      "Epoch: 5300 Loss: 0.13\n",
      "Epoch: 5400 Loss: 0.13\n",
      "Epoch: 5400 Loss: 0.13\n",
      "Epoch: 5400 Loss: 0.13\n",
      "Epoch: 5400 Loss: 0.13\n",
      "Epoch: 5500 Loss: 0.13\n",
      "Epoch: 5500 Loss: 0.13\n",
      "Epoch: 5500 Loss: 0.13\n",
      "Epoch: 5500 Loss: 0.13\n",
      "Epoch: 5600 Loss: 0.13\n",
      "Epoch: 5600 Loss: 0.13\n",
      "Epoch: 5600 Loss: 0.13\n",
      "Epoch: 5600 Loss: 0.13\n",
      "Epoch: 5700 Loss: 0.13\n",
      "Epoch: 5700 Loss: 0.13\n",
      "Epoch: 5700 Loss: 0.13\n",
      "Epoch: 5700 Loss: 0.13\n",
      "Epoch: 5800 Loss: 0.13\n",
      "Epoch: 5800 Loss: 0.13\n",
      "Epoch: 5800 Loss: 0.13\n",
      "Epoch: 5800 Loss: 0.13\n",
      "Epoch: 5900 Loss: 0.13\n",
      "Epoch: 5900 Loss: 0.13\n",
      "Epoch: 5900 Loss: 0.13\n",
      "Epoch: 5900 Loss: 0.13\n",
      "Epoch: 6000 Loss: 0.13\n",
      "Epoch: 6000 Loss: 0.13\n",
      "Epoch: 6000 Loss: 0.13\n",
      "Epoch: 6000 Loss: 0.13\n",
      "Epoch: 6100 Loss: 0.13\n",
      "Epoch: 6100 Loss: 0.13\n",
      "Epoch: 6100 Loss: 0.13\n",
      "Epoch: 6100 Loss: 0.13\n",
      "Epoch: 6200 Loss: 0.13\n",
      "Epoch: 6200 Loss: 0.13\n",
      "Epoch: 6200 Loss: 0.13\n",
      "Epoch: 6200 Loss: 0.13\n",
      "Epoch: 6300 Loss: 0.13\n",
      "Epoch: 6300 Loss: 0.13\n",
      "Epoch: 6300 Loss: 0.13\n",
      "Epoch: 6300 Loss: 0.13\n",
      "Epoch: 6400 Loss: 0.13\n",
      "Epoch: 6400 Loss: 0.13\n",
      "Epoch: 6400 Loss: 0.13\n",
      "Epoch: 6400 Loss: 0.13\n",
      "Epoch: 6500 Loss: 0.13\n",
      "Epoch: 6500 Loss: 0.13\n",
      "Epoch: 6500 Loss: 0.13\n",
      "Epoch: 6500 Loss: 0.13\n",
      "Epoch: 6600 Loss: 0.13\n",
      "Epoch: 6600 Loss: 0.13\n",
      "Epoch: 6600 Loss: 0.13\n",
      "Epoch: 6600 Loss: 0.13\n",
      "Epoch: 6700 Loss: 0.13\n",
      "Epoch: 6700 Loss: 0.13\n",
      "Epoch: 6700 Loss: 0.13\n",
      "Epoch: 6700 Loss: 0.13\n",
      "Epoch: 6800 Loss: 0.13\n",
      "Epoch: 6800 Loss: 0.13\n",
      "Epoch: 6800 Loss: 0.13\n",
      "Epoch: 6800 Loss: 0.13\n",
      "Epoch: 6900 Loss: 0.13\n",
      "Epoch: 6900 Loss: 0.13\n",
      "Epoch: 6900 Loss: 0.13\n",
      "Epoch: 6900 Loss: 0.13\n",
      "Epoch: 7000 Loss: 0.13\n",
      "Epoch: 7000 Loss: 0.13\n",
      "Epoch: 7000 Loss: 0.13\n",
      "Epoch: 7000 Loss: 0.13\n",
      "Epoch: 7100 Loss: 0.13\n",
      "Epoch: 7100 Loss: 0.13\n",
      "Epoch: 7100 Loss: 0.13\n",
      "Epoch: 7100 Loss: 0.13\n",
      "Epoch: 7200 Loss: 0.13\n",
      "Epoch: 7200 Loss: 0.13\n",
      "Epoch: 7200 Loss: 0.13\n",
      "Epoch: 7200 Loss: 0.13\n",
      "Epoch: 7300 Loss: 0.13\n",
      "Epoch: 7300 Loss: 0.13\n",
      "Epoch: 7300 Loss: 0.13\n",
      "Epoch: 7300 Loss: 0.13\n",
      "Epoch: 7400 Loss: 0.13\n",
      "Epoch: 7400 Loss: 0.13\n",
      "Epoch: 7400 Loss: 0.13\n",
      "Epoch: 7400 Loss: 0.13\n",
      "Epoch: 7500 Loss: 0.13\n",
      "Epoch: 7500 Loss: 0.13\n",
      "Epoch: 7500 Loss: 0.13\n",
      "Epoch: 7500 Loss: 0.13\n",
      "Epoch: 7600 Loss: 0.13\n",
      "Epoch: 7600 Loss: 0.13\n",
      "Epoch: 7600 Loss: 0.13\n",
      "Epoch: 7600 Loss: 0.13\n",
      "Epoch: 7700 Loss: 0.13\n",
      "Epoch: 7700 Loss: 0.13\n",
      "Epoch: 7700 Loss: 0.13\n",
      "Epoch: 7700 Loss: 0.13\n",
      "Epoch: 7800 Loss: 0.13\n",
      "Epoch: 7800 Loss: 0.13\n",
      "Epoch: 7800 Loss: 0.13\n",
      "Epoch: 7800 Loss: 0.13\n",
      "Epoch: 7900 Loss: 0.12\n",
      "Epoch: 7900 Loss: 0.12\n",
      "Epoch: 7900 Loss: 0.12\n",
      "Epoch: 7900 Loss: 0.12\n",
      "Epoch: 8000 Loss: 0.12\n",
      "Epoch: 8000 Loss: 0.12\n",
      "Epoch: 8000 Loss: 0.12\n",
      "Epoch: 8000 Loss: 0.12\n",
      "Epoch: 8100 Loss: 0.12\n",
      "Epoch: 8100 Loss: 0.12\n",
      "Epoch: 8100 Loss: 0.12\n",
      "Epoch: 8100 Loss: 0.12\n",
      "Epoch: 8200 Loss: 0.12\n",
      "Epoch: 8200 Loss: 0.12\n",
      "Epoch: 8200 Loss: 0.12\n",
      "Epoch: 8200 Loss: 0.12\n",
      "Epoch: 8300 Loss: 0.12\n",
      "Epoch: 8300 Loss: 0.12\n",
      "Epoch: 8300 Loss: 0.12\n",
      "Epoch: 8300 Loss: 0.12\n",
      "Epoch: 8400 Loss: 0.12\n",
      "Epoch: 8400 Loss: 0.12\n",
      "Epoch: 8400 Loss: 0.12\n",
      "Epoch: 8400 Loss: 0.12\n",
      "Epoch: 8500 Loss: 0.11\n",
      "Epoch: 8500 Loss: 0.11\n",
      "Epoch: 8500 Loss: 0.11\n",
      "Epoch: 8500 Loss: 0.11\n",
      "Epoch: 8600 Loss: 0.09\n",
      "Epoch: 8600 Loss: 0.09\n",
      "Epoch: 8600 Loss: 0.09\n",
      "Epoch: 8600 Loss: 0.08\n",
      "Epoch: 8700 Loss: 0.02\n",
      "Epoch: 8700 Loss: 0.02\n",
      "Epoch: 8700 Loss: 0.02\n",
      "Epoch: 8700 Loss: 0.02\n",
      "Epoch: 8800 Loss: 0.01\n",
      "Epoch: 8800 Loss: 0.01\n",
      "Epoch: 8800 Loss: 0.01\n",
      "Epoch: 8800 Loss: 0.01\n",
      "Epoch: 8900 Loss: 0.01\n",
      "Epoch: 8900 Loss: 0.01\n",
      "Epoch: 8900 Loss: 0.01\n",
      "Epoch: 8900 Loss: 0.01\n",
      "Epoch: 9000 Loss: 0.01\n",
      "Epoch: 9000 Loss: 0.01\n",
      "Epoch: 9000 Loss: 0.01\n",
      "Epoch: 9000 Loss: 0.01\n",
      "Epoch: 9100 Loss: 0.01\n",
      "Epoch: 9100 Loss: 0.01\n",
      "Epoch: 9100 Loss: 0.01\n",
      "Epoch: 9100 Loss: 0.01\n",
      "Epoch: 9200 Loss: 0.01\n",
      "Epoch: 9200 Loss: 0.01\n",
      "Epoch: 9200 Loss: 0.01\n",
      "Epoch: 9200 Loss: 0.01\n",
      "Epoch: 9300 Loss: 0.00\n",
      "Epoch: 9300 Loss: 0.00\n",
      "Epoch: 9300 Loss: 0.00\n",
      "Epoch: 9300 Loss: 0.00\n",
      "Epoch: 9400 Loss: 0.00\n",
      "Epoch: 9400 Loss: 0.00\n",
      "Epoch: 9400 Loss: 0.00\n",
      "Epoch: 9400 Loss: 0.00\n",
      "Epoch: 9500 Loss: 0.00\n",
      "Epoch: 9500 Loss: 0.00\n",
      "Epoch: 9500 Loss: 0.00\n",
      "Epoch: 9500 Loss: 0.00\n",
      "Epoch: 9600 Loss: 0.00\n",
      "Epoch: 9600 Loss: 0.00\n",
      "Epoch: 9600 Loss: 0.00\n",
      "Epoch: 9600 Loss: 0.00\n",
      "Epoch: 9700 Loss: 0.00\n",
      "Epoch: 9700 Loss: 0.00\n",
      "Epoch: 9700 Loss: 0.00\n",
      "Epoch: 9700 Loss: 0.00\n",
      "Epoch: 9800 Loss: 0.00\n",
      "Epoch: 9800 Loss: 0.00\n",
      "Epoch: 9800 Loss: 0.00\n",
      "Epoch: 9800 Loss: 0.00\n",
      "Epoch: 9900 Loss: 0.00\n",
      "Epoch: 9900 Loss: 0.00\n",
      "Epoch: 9900 Loss: 0.00\n",
      "Epoch: 9900 Loss: 0.00\n",
      "Epoch: 10000 Loss: 0.00\n",
      "Epoch: 10000 Loss: 0.00\n",
      "Epoch: 10000 Loss: 0.00\n",
      "Epoch: 10000 Loss: 0.00\n",
      "Epoch: 10100 Loss: 0.00\n",
      "Epoch: 10100 Loss: 0.00\n",
      "Epoch: 10100 Loss: 0.00\n",
      "Epoch: 10100 Loss: 0.00\n",
      "Epoch: 10200 Loss: 0.00\n",
      "Epoch: 10200 Loss: 0.00\n",
      "Epoch: 10200 Loss: 0.00\n",
      "Epoch: 10200 Loss: 0.00\n",
      "Epoch: 10300 Loss: 0.00\n",
      "Epoch: 10300 Loss: 0.00\n",
      "Epoch: 10300 Loss: 0.00\n",
      "Epoch: 10300 Loss: 0.00\n",
      "Epoch: 10400 Loss: 0.00\n",
      "Epoch: 10400 Loss: 0.00\n",
      "Epoch: 10400 Loss: 0.00\n",
      "Epoch: 10400 Loss: 0.00\n",
      "Epoch: 10500 Loss: 0.00\n",
      "Epoch: 10500 Loss: 0.00\n",
      "Epoch: 10500 Loss: 0.00\n",
      "Epoch: 10500 Loss: 0.00\n",
      "Epoch: 10600 Loss: 0.00\n",
      "Epoch: 10600 Loss: 0.00\n",
      "Epoch: 10600 Loss: 0.00\n",
      "Epoch: 10600 Loss: 0.00\n",
      "Epoch: 10700 Loss: 0.00\n",
      "Epoch: 10700 Loss: 0.00\n",
      "Epoch: 10700 Loss: 0.00\n",
      "Epoch: 10700 Loss: 0.00\n",
      "Epoch: 10800 Loss: 0.00\n",
      "Epoch: 10800 Loss: 0.00\n",
      "Epoch: 10800 Loss: 0.00\n",
      "Epoch: 10800 Loss: 0.00\n",
      "Epoch: 10900 Loss: 0.00\n",
      "Epoch: 10900 Loss: 0.00\n",
      "Epoch: 10900 Loss: 0.00\n",
      "Epoch: 10900 Loss: 0.00\n",
      "Epoch: 11000 Loss: 0.00\n",
      "Epoch: 11000 Loss: 0.00\n",
      "Epoch: 11000 Loss: 0.00\n",
      "Epoch: 11000 Loss: 0.00\n",
      "Epoch: 11100 Loss: 0.00\n",
      "Epoch: 11100 Loss: 0.00\n",
      "Epoch: 11100 Loss: 0.00\n",
      "Epoch: 11100 Loss: 0.00\n",
      "Epoch: 11200 Loss: 0.00\n",
      "Epoch: 11200 Loss: 0.00\n",
      "Epoch: 11200 Loss: 0.00\n",
      "Epoch: 11200 Loss: 0.00\n",
      "Epoch: 11300 Loss: 0.00\n",
      "Epoch: 11300 Loss: 0.00\n",
      "Epoch: 11300 Loss: 0.00\n",
      "Epoch: 11300 Loss: 0.00\n",
      "Epoch: 11400 Loss: 0.00\n",
      "Epoch: 11400 Loss: 0.00\n",
      "Epoch: 11400 Loss: 0.00\n",
      "Epoch: 11400 Loss: 0.00\n",
      "Epoch: 11500 Loss: 0.00\n",
      "Epoch: 11500 Loss: 0.00\n",
      "Epoch: 11500 Loss: 0.00\n",
      "Epoch: 11500 Loss: 0.00\n",
      "Epoch: 11600 Loss: 0.00\n",
      "Epoch: 11600 Loss: 0.00\n",
      "Epoch: 11600 Loss: 0.00\n",
      "Epoch: 11600 Loss: 0.00\n",
      "Epoch: 11700 Loss: 0.00\n",
      "Epoch: 11700 Loss: 0.00\n",
      "Epoch: 11700 Loss: 0.00\n",
      "Epoch: 11700 Loss: 0.00\n",
      "Epoch: 11800 Loss: 0.00\n",
      "Epoch: 11800 Loss: 0.00\n",
      "Epoch: 11800 Loss: 0.00\n",
      "Epoch: 11800 Loss: 0.00\n",
      "Epoch: 11900 Loss: 0.00\n",
      "Epoch: 11900 Loss: 0.00\n",
      "Epoch: 11900 Loss: 0.00\n",
      "Epoch: 11900 Loss: 0.00\n",
      "Epoch: 12000 Loss: 0.00\n",
      "Epoch: 12000 Loss: 0.00\n",
      "Epoch: 12000 Loss: 0.00\n",
      "Epoch: 12000 Loss: 0.00\n",
      "Epoch: 12100 Loss: 0.00\n",
      "Epoch: 12100 Loss: 0.00\n",
      "Epoch: 12100 Loss: 0.00\n",
      "Epoch: 12100 Loss: 0.00\n",
      "Epoch: 12200 Loss: 0.00\n",
      "Epoch: 12200 Loss: 0.00\n",
      "Epoch: 12200 Loss: 0.00\n",
      "Epoch: 12200 Loss: 0.00\n",
      "Epoch: 12300 Loss: 0.00\n",
      "Epoch: 12300 Loss: 0.00\n",
      "Epoch: 12300 Loss: 0.00\n",
      "Epoch: 12300 Loss: 0.00\n",
      "Epoch: 12400 Loss: 0.00\n",
      "Epoch: 12400 Loss: 0.00\n",
      "Epoch: 12400 Loss: 0.00\n",
      "Epoch: 12400 Loss: 0.00\n",
      "Epoch: 12500 Loss: 0.00\n",
      "Epoch: 12500 Loss: 0.00\n",
      "Epoch: 12500 Loss: 0.00\n",
      "Epoch: 12500 Loss: 0.00\n",
      "Epoch: 12600 Loss: 0.00\n",
      "Epoch: 12600 Loss: 0.00\n",
      "Epoch: 12600 Loss: 0.00\n",
      "Epoch: 12600 Loss: 0.00\n",
      "Epoch: 12700 Loss: 0.00\n",
      "Epoch: 12700 Loss: 0.00\n",
      "Epoch: 12700 Loss: 0.00\n",
      "Epoch: 12700 Loss: 0.00\n",
      "Epoch: 12800 Loss: 0.00\n",
      "Epoch: 12800 Loss: 0.00\n",
      "Epoch: 12800 Loss: 0.00\n",
      "Epoch: 12800 Loss: 0.00\n",
      "Epoch: 12900 Loss: 0.00\n",
      "Epoch: 12900 Loss: 0.00\n",
      "Epoch: 12900 Loss: 0.00\n",
      "Epoch: 12900 Loss: 0.00\n",
      "Epoch: 13000 Loss: 0.00\n",
      "Epoch: 13000 Loss: 0.00\n",
      "Epoch: 13000 Loss: 0.00\n",
      "Epoch: 13000 Loss: 0.00\n",
      "Epoch: 13100 Loss: 0.00\n",
      "Epoch: 13100 Loss: 0.00\n",
      "Epoch: 13100 Loss: 0.00\n",
      "Epoch: 13100 Loss: 0.00\n",
      "Epoch: 13200 Loss: 0.00\n",
      "Epoch: 13200 Loss: 0.00\n",
      "Epoch: 13200 Loss: 0.00\n",
      "Epoch: 13200 Loss: 0.00\n",
      "Epoch: 13300 Loss: 0.00\n",
      "Epoch: 13300 Loss: 0.00\n",
      "Epoch: 13300 Loss: 0.00\n",
      "Epoch: 13300 Loss: 0.00\n",
      "Epoch: 13400 Loss: 0.00\n",
      "Epoch: 13400 Loss: 0.00\n",
      "Epoch: 13400 Loss: 0.00\n",
      "Epoch: 13400 Loss: 0.00\n",
      "Epoch: 13500 Loss: 0.00\n",
      "Epoch: 13500 Loss: 0.00\n",
      "Epoch: 13500 Loss: 0.00\n",
      "Epoch: 13500 Loss: 0.00\n",
      "Epoch: 13600 Loss: 0.00\n",
      "Epoch: 13600 Loss: 0.00\n",
      "Epoch: 13600 Loss: 0.00\n",
      "Epoch: 13600 Loss: 0.00\n",
      "Epoch: 13700 Loss: 0.00\n",
      "Epoch: 13700 Loss: 0.00\n",
      "Epoch: 13700 Loss: 0.00\n",
      "Epoch: 13700 Loss: 0.00\n",
      "Epoch: 13800 Loss: 0.00\n",
      "Epoch: 13800 Loss: 0.00\n",
      "Epoch: 13800 Loss: 0.00\n",
      "Epoch: 13800 Loss: 0.00\n",
      "Epoch: 13900 Loss: 0.00\n",
      "Epoch: 13900 Loss: 0.00\n",
      "Epoch: 13900 Loss: 0.00\n",
      "Epoch: 13900 Loss: 0.00\n",
      "Epoch: 14000 Loss: 0.00\n",
      "Epoch: 14000 Loss: 0.00\n",
      "Epoch: 14000 Loss: 0.00\n",
      "Epoch: 14000 Loss: 0.00\n",
      "Epoch: 14100 Loss: 0.00\n",
      "Epoch: 14100 Loss: 0.00\n",
      "Epoch: 14100 Loss: 0.00\n",
      "Epoch: 14100 Loss: 0.00\n",
      "Epoch: 14200 Loss: 0.00\n",
      "Epoch: 14200 Loss: 0.00\n",
      "Epoch: 14200 Loss: 0.00\n",
      "Epoch: 14200 Loss: 0.00\n",
      "Epoch: 14300 Loss: 0.00\n",
      "Epoch: 14300 Loss: 0.00\n",
      "Epoch: 14300 Loss: 0.00\n",
      "Epoch: 14300 Loss: 0.00\n",
      "Epoch: 14400 Loss: 0.00\n",
      "Epoch: 14400 Loss: 0.00\n",
      "Epoch: 14400 Loss: 0.00\n",
      "Epoch: 14400 Loss: 0.00\n",
      "Epoch: 14500 Loss: 0.00\n",
      "Epoch: 14500 Loss: 0.00\n",
      "Epoch: 14500 Loss: 0.00\n",
      "Epoch: 14500 Loss: 0.00\n",
      "Epoch: 14600 Loss: 0.00\n",
      "Epoch: 14600 Loss: 0.00\n",
      "Epoch: 14600 Loss: 0.00\n",
      "Epoch: 14600 Loss: 0.00\n",
      "Epoch: 14700 Loss: 0.00\n",
      "Epoch: 14700 Loss: 0.00\n",
      "Epoch: 14700 Loss: 0.00\n",
      "Epoch: 14700 Loss: 0.00\n",
      "Epoch: 14800 Loss: 0.00\n",
      "Epoch: 14800 Loss: 0.00\n",
      "Epoch: 14800 Loss: 0.00\n",
      "Epoch: 14800 Loss: 0.00\n",
      "Epoch: 14900 Loss: 0.00\n",
      "Epoch: 14900 Loss: 0.00\n",
      "Epoch: 14900 Loss: 0.00\n",
      "Epoch: 14900 Loss: 0.00\n",
      "Epoch: 15000 Loss: 0.00\n",
      "Epoch: 15000 Loss: 0.00\n",
      "Epoch: 15000 Loss: 0.00\n",
      "Epoch: 15000 Loss: 0.00\n",
      "Epoch: 15100 Loss: 0.00\n",
      "Epoch: 15100 Loss: 0.00\n",
      "Epoch: 15100 Loss: 0.00\n",
      "Epoch: 15100 Loss: 0.00\n",
      "Epoch: 15200 Loss: 0.00\n",
      "Epoch: 15200 Loss: 0.00\n",
      "Epoch: 15200 Loss: 0.00\n",
      "Epoch: 15200 Loss: 0.00\n",
      "Epoch: 15300 Loss: 0.00\n",
      "Epoch: 15300 Loss: 0.00\n",
      "Epoch: 15300 Loss: 0.00\n",
      "Epoch: 15300 Loss: 0.00\n",
      "Epoch: 15400 Loss: 0.00\n",
      "Epoch: 15400 Loss: 0.00\n",
      "Epoch: 15400 Loss: 0.00\n",
      "Epoch: 15400 Loss: 0.00\n",
      "Epoch: 15500 Loss: 0.00\n",
      "Epoch: 15500 Loss: 0.00\n",
      "Epoch: 15500 Loss: 0.00\n",
      "Epoch: 15500 Loss: 0.00\n",
      "Epoch: 15600 Loss: 0.00\n",
      "Epoch: 15600 Loss: 0.00\n",
      "Epoch: 15600 Loss: 0.00\n",
      "Epoch: 15600 Loss: 0.00\n",
      "Epoch: 15700 Loss: 0.00\n",
      "Epoch: 15700 Loss: 0.00\n",
      "Epoch: 15700 Loss: 0.00\n",
      "Epoch: 15700 Loss: 0.00\n",
      "Epoch: 15800 Loss: 0.00\n",
      "Epoch: 15800 Loss: 0.00\n",
      "Epoch: 15800 Loss: 0.00\n",
      "Epoch: 15800 Loss: 0.00\n",
      "Epoch: 15900 Loss: 0.00\n",
      "Epoch: 15900 Loss: 0.00\n",
      "Epoch: 15900 Loss: 0.00\n",
      "Epoch: 15900 Loss: 0.00\n",
      "Epoch: 16000 Loss: 0.00\n",
      "Epoch: 16000 Loss: 0.00\n",
      "Epoch: 16000 Loss: 0.00\n",
      "Epoch: 16000 Loss: 0.00\n",
      "Epoch: 16100 Loss: 0.00\n",
      "Epoch: 16100 Loss: 0.00\n",
      "Epoch: 16100 Loss: 0.00\n",
      "Epoch: 16100 Loss: 0.00\n",
      "Epoch: 16200 Loss: 0.00\n",
      "Epoch: 16200 Loss: 0.00\n",
      "Epoch: 16200 Loss: 0.00\n",
      "Epoch: 16200 Loss: 0.00\n",
      "Epoch: 16300 Loss: 0.00\n",
      "Epoch: 16300 Loss: 0.00\n",
      "Epoch: 16300 Loss: 0.00\n",
      "Epoch: 16300 Loss: 0.00\n",
      "Epoch: 16400 Loss: 0.00\n",
      "Epoch: 16400 Loss: 0.00\n",
      "Epoch: 16400 Loss: 0.00\n",
      "Epoch: 16400 Loss: 0.00\n",
      "Epoch: 16500 Loss: 0.00\n",
      "Epoch: 16500 Loss: 0.00\n",
      "Epoch: 16500 Loss: 0.00\n",
      "Epoch: 16500 Loss: 0.00\n",
      "Epoch: 16600 Loss: 0.00\n",
      "Epoch: 16600 Loss: 0.00\n",
      "Epoch: 16600 Loss: 0.00\n",
      "Epoch: 16600 Loss: 0.00\n",
      "Epoch: 16700 Loss: 0.00\n",
      "Epoch: 16700 Loss: 0.00\n",
      "Epoch: 16700 Loss: 0.00\n",
      "Epoch: 16700 Loss: 0.00\n",
      "Epoch: 16800 Loss: 0.00\n",
      "Epoch: 16800 Loss: 0.00\n",
      "Epoch: 16800 Loss: 0.00\n",
      "Epoch: 16800 Loss: 0.00\n",
      "Epoch: 16900 Loss: 0.00\n",
      "Epoch: 16900 Loss: 0.00\n",
      "Epoch: 16900 Loss: 0.00\n",
      "Epoch: 16900 Loss: 0.00\n",
      "Epoch: 17000 Loss: 0.00\n",
      "Epoch: 17000 Loss: 0.00\n",
      "Epoch: 17000 Loss: 0.00\n",
      "Epoch: 17000 Loss: 0.00\n",
      "Epoch: 17100 Loss: 0.00\n",
      "Epoch: 17100 Loss: 0.00\n",
      "Epoch: 17100 Loss: 0.00\n",
      "Epoch: 17100 Loss: 0.00\n",
      "Epoch: 17200 Loss: 0.00\n",
      "Epoch: 17200 Loss: 0.00\n",
      "Epoch: 17200 Loss: 0.00\n",
      "Epoch: 17200 Loss: 0.00\n",
      "Epoch: 17300 Loss: 0.00\n",
      "Epoch: 17300 Loss: 0.00\n",
      "Epoch: 17300 Loss: 0.00\n",
      "Epoch: 17300 Loss: 0.00\n",
      "Epoch: 17400 Loss: 0.00\n",
      "Epoch: 17400 Loss: 0.00\n",
      "Epoch: 17400 Loss: 0.00\n",
      "Epoch: 17400 Loss: 0.00\n",
      "Epoch: 17500 Loss: 0.00\n",
      "Epoch: 17500 Loss: 0.00\n",
      "Epoch: 17500 Loss: 0.00\n",
      "Epoch: 17500 Loss: 0.00\n",
      "Epoch: 17600 Loss: 0.00\n",
      "Epoch: 17600 Loss: 0.00\n",
      "Epoch: 17600 Loss: 0.00\n",
      "Epoch: 17600 Loss: 0.00\n",
      "Epoch: 17700 Loss: 0.00\n",
      "Epoch: 17700 Loss: 0.00\n",
      "Epoch: 17700 Loss: 0.00\n",
      "Epoch: 17700 Loss: 0.00\n",
      "Epoch: 17800 Loss: 0.00\n",
      "Epoch: 17800 Loss: 0.00\n",
      "Epoch: 17800 Loss: 0.00\n",
      "Epoch: 17800 Loss: 0.00\n",
      "Epoch: 17900 Loss: 0.00\n",
      "Epoch: 17900 Loss: 0.00\n",
      "Epoch: 17900 Loss: 0.00\n",
      "Epoch: 17900 Loss: 0.00\n",
      "Epoch: 18000 Loss: 0.00\n",
      "Epoch: 18000 Loss: 0.00\n",
      "Epoch: 18000 Loss: 0.00\n",
      "Epoch: 18000 Loss: 0.00\n",
      "Epoch: 18100 Loss: 0.00\n",
      "Epoch: 18100 Loss: 0.00\n",
      "Epoch: 18100 Loss: 0.00\n",
      "Epoch: 18100 Loss: 0.00\n",
      "Epoch: 18200 Loss: 0.00\n",
      "Epoch: 18200 Loss: 0.00\n",
      "Epoch: 18200 Loss: 0.00\n",
      "Epoch: 18200 Loss: 0.00\n",
      "Epoch: 18300 Loss: 0.00\n",
      "Epoch: 18300 Loss: 0.00\n",
      "Epoch: 18300 Loss: 0.00\n",
      "Epoch: 18300 Loss: 0.00\n",
      "Epoch: 18400 Loss: 0.00\n",
      "Epoch: 18400 Loss: 0.00\n",
      "Epoch: 18400 Loss: 0.00\n",
      "Epoch: 18400 Loss: 0.00\n",
      "Epoch: 18500 Loss: 0.00\n",
      "Epoch: 18500 Loss: 0.00\n",
      "Epoch: 18500 Loss: 0.00\n",
      "Epoch: 18500 Loss: 0.00\n",
      "Epoch: 18600 Loss: 0.00\n",
      "Epoch: 18600 Loss: 0.00\n",
      "Epoch: 18600 Loss: 0.00\n",
      "Epoch: 18600 Loss: 0.00\n",
      "Epoch: 18700 Loss: 0.00\n",
      "Epoch: 18700 Loss: 0.00\n",
      "Epoch: 18700 Loss: 0.00\n",
      "Epoch: 18700 Loss: 0.00\n",
      "Epoch: 18800 Loss: 0.00\n",
      "Epoch: 18800 Loss: 0.00\n",
      "Epoch: 18800 Loss: 0.00\n",
      "Epoch: 18800 Loss: 0.00\n",
      "Epoch: 18900 Loss: 0.00\n",
      "Epoch: 18900 Loss: 0.00\n",
      "Epoch: 18900 Loss: 0.00\n",
      "Epoch: 18900 Loss: 0.00\n",
      "Epoch: 19000 Loss: 0.00\n",
      "Epoch: 19000 Loss: 0.00\n",
      "Epoch: 19000 Loss: 0.00\n",
      "Epoch: 19000 Loss: 0.00\n",
      "Epoch: 19100 Loss: 0.00\n",
      "Epoch: 19100 Loss: 0.00\n",
      "Epoch: 19100 Loss: 0.00\n",
      "Epoch: 19100 Loss: 0.00\n",
      "Epoch: 19200 Loss: 0.00\n",
      "Epoch: 19200 Loss: 0.00\n",
      "Epoch: 19200 Loss: 0.00\n",
      "Epoch: 19200 Loss: 0.00\n",
      "Epoch: 19300 Loss: 0.00\n",
      "Epoch: 19300 Loss: 0.00\n",
      "Epoch: 19300 Loss: 0.00\n",
      "Epoch: 19300 Loss: 0.00\n",
      "Epoch: 19400 Loss: 0.00\n",
      "Epoch: 19400 Loss: 0.00\n",
      "Epoch: 19400 Loss: 0.00\n",
      "Epoch: 19400 Loss: 0.00\n",
      "Epoch: 19500 Loss: 0.00\n",
      "Epoch: 19500 Loss: 0.00\n",
      "Epoch: 19500 Loss: 0.00\n",
      "Epoch: 19500 Loss: 0.00\n",
      "Epoch: 19600 Loss: 0.00\n",
      "Epoch: 19600 Loss: 0.00\n",
      "Epoch: 19600 Loss: 0.00\n",
      "Epoch: 19600 Loss: 0.00\n",
      "Epoch: 19700 Loss: 0.00\n",
      "Epoch: 19700 Loss: 0.00\n",
      "Epoch: 19700 Loss: 0.00\n",
      "Epoch: 19700 Loss: 0.00\n",
      "Epoch: 19800 Loss: 0.00\n",
      "Epoch: 19800 Loss: 0.00\n",
      "Epoch: 19800 Loss: 0.00\n",
      "Epoch: 19800 Loss: 0.00\n",
      "Epoch: 19900 Loss: 0.00\n",
      "Epoch: 19900 Loss: 0.00\n",
      "Epoch: 19900 Loss: 0.00\n",
      "Epoch: 19900 Loss: 0.00\n",
      "Epoch: 20000 Loss: 0.00\n",
      "Epoch: 20000 Loss: 0.00\n",
      "Epoch: 20000 Loss: 0.00\n",
      "Epoch: 20000 Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Aqui se definen los parametros para el entrenamiento del set para XOR\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "#Se define una red neuronal con 2 capas ocultas y una de salida\n",
    "nn = NeuralNetwork([2, 2, 1], alpha=0.5)\n",
    "#Se definen 20000 epochs para el entrenamiento\n",
    "nn.fit(X, y, epochs=20000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data=[0 0], ground-truth=0, pred=0.0148, step=0\n",
      "[INFO] data=[0 1], ground-truth=1, pred=0.9870, step=1\n",
      "[INFO] data=[1 0], ground-truth=1, pred=0.9882, step=1\n",
      "[INFO] data=[1 1], ground-truth=0, pred=0.0113, step=0\n"
     ]
    }
   ],
   "source": [
    "#Se hace un ciclo entre los datos de prueba del set para XOR\n",
    "for (x, target) in zip(X, y):\n",
    "    #Se calcula la predicción de la red para cada dato\n",
    "    pred = nn.predict(x)[0][0]\n",
    "    step = 1 if pred > 0.5 else 0\n",
    "    print(\"[INFO] data={}, ground-truth={}, pred={:.4f}, step={}\".format(x, target[0], pred, step))\n",
    "    #En los resultados se puede notar que la red aprendió correctamente el patrón de XOR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%for (x, target) in zip(X, y):\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se grafiga la pérdida para cada epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(nn.epoch_data, nn.loss_data)\n",
    "\n",
    "\n",
    "plt.title('Pérdida en entrenamiento XOR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}